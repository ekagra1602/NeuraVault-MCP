# Memora MCP - Development Guide

A universal memory layer for AI models supporting OpenAI, Gemini, Claude, Grok, and any LLM with context protocol support.

## ğŸš€ Quick Start

### One-Command Setup
```bash
./setup.sh
```

### Manual Setup

#### Backend (Python FastAPI)
```bash
# Create virtual environment
python3 -m venv .venv
source .venv/bin/activate

# Install dependencies  
pip install -r requirements.txt

# Start backend
uvicorn app.main:app --reload
```

#### Frontend (React + TypeScript)
```bash
# Install dependencies
cd frontend
npm install

# Start development server
npm run dev
```

## ğŸ“ Project Structure

```
mcp/
â”œâ”€â”€ app/                    # Python FastAPI backend
â”‚   â”œâ”€â”€ __init__.py        # Memory management utilities
â”‚   â”œâ”€â”€ main.py            # FastAPI app and routes
â”‚   â”œâ”€â”€ memory.py          # Memory store implementation
â”‚   â”œâ”€â”€ config.py          # Configuration management
â”‚   â””â”€â”€ routers/           # API route modules
â”œâ”€â”€ frontend/              # React TypeScript frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/    # React components
â”‚   â”‚   â”œâ”€â”€ pages/        # Page components
â”‚   â”‚   â””â”€â”€ lib/          # Utilities
â”‚   â”œâ”€â”€ package.json      # Node.js dependencies
â”‚   â””â”€â”€ vite.config.ts    # Vite configuration
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ .gitignore            # Git ignore rules
â”œâ”€â”€ setup.sh              # Project setup script
â”œâ”€â”€ start-backend.sh      # Backend startup script
â””â”€â”€ start-frontend.sh     # Frontend startup script
```

## ğŸ› ï¸ Development Scripts

| Script | Purpose |
|--------|---------|
| `./setup.sh` | Complete project setup (backend + frontend) |
| `./start-backend.sh` | Start FastAPI server |
| `./start-frontend.sh` | Start React development server |

## ğŸŒ URLs

- **Backend API**: http://localhost:8000
- **Frontend**: http://localhost:5173  
- **API Documentation**: http://localhost:8000/docs
- **Interactive API**: http://localhost:8000/redoc

## ğŸ”§ Configuration

### Environment Variables
Copy `env.example` to `.env` and configure:

```bash
cp env.example .env
```

### Backend Configuration
- **Host**: `0.0.0.0` (configurable via `HOST` env var)
- **Port**: `8000` (configurable via `PORT` env var)
- **Debug**: `True` in development

### Frontend Configuration
- **Vite Dev Server**: Port 5173
- **API Proxy**: `/api` routes proxy to backend
- **Hot Reload**: Enabled in development

## ğŸ“¦ Dependencies

### Backend (Python)
- **FastAPI**: Web framework
- **Uvicorn**: ASGI server
- **Pydantic**: Data validation
- **Python-dotenv**: Environment management

### Frontend (React)
- **React 18**: UI framework
- **TypeScript**: Type safety
- **Vite**: Build tool
- **Tailwind CSS**: Styling
- **Framer Motion**: Animations
- **Lucide React**: Icons

## ğŸš« Git Ignore

The `.gitignore` includes:
- `node_modules/` - Frontend dependencies
- `__pycache__/` - Python cache
- `.venv/` - Virtual environment
- `dist/` - Build outputs
- `.env` - Environment variables
- Editor and OS files

## ğŸ§ª Testing

### Backend Testing
```bash
source .venv/bin/activate
python -m pytest
```

### Frontend Testing
```bash
cd frontend
npm test
```

## ğŸ“ API Usage Examples

### Store Memory
```bash
curl -X POST "http://localhost:8000/memory" \
  -H "Content-Type: application/json" \
  -d '{
    "user_id": "alice",
    "llm": "gpt-4o",
    "content": "Alice prefers concise explanations"
  }'
```

### Retrieve Memories
```bash
curl "http://localhost:8000/memory/alice"
```

### Multi-LLM Context
```python
from app.memory import MemoryItem, memory_store

# Store from different models
models = ["gpt-4o", "claude-3-opus", "gemini-pro", "grok-1"]
for model in models:
    memory_store.add(MemoryItem(
        user_id="bob",
        llm=model,
        content=f"User preference learned via {model}"
    ))

# Retrieve all cross-model memories
memories = memory_store.get("bob")
```

## ğŸ” Troubleshooting

### Common Issues

1. **Port already in use**
   ```bash
   # Kill process on port 8000
   lsof -ti:8000 | xargs kill -9
   ```

2. **Python virtual environment issues**
   ```bash
   # Recreate virtual environment
   rm -rf .venv
   python3 -m venv .venv
   source .venv/bin/activate
   pip install -r requirements.txt
   ```

3. **Node modules issues**
   ```bash
   # Clear and reinstall
   cd frontend
   rm -rf node_modules package-lock.json
   npm install
   ```

## ğŸš€ Production Deployment

### Backend
```bash
# Production server
gunicorn app.main:app -w 4 -k uvicorn.workers.UvicornWorker

# Or with uvicorn
uvicorn app.main:app --host 0.0.0.0 --port 8000 --workers 4
```

### Frontend
```bash
cd frontend
npm run build
# Serve dist/ folder with nginx or similar
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request

## ğŸ“„ License

MIT License - see LICENSE file for details.
